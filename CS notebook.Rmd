---
title: "R Notebook for Composite Score"
output:
  html_document: default
  html_notebook: default
  pdf_document: default
  word_document: default
---

#Introduction
authored by Joshua J Kellogg

This notebook contains the R scripts for calculating the composite score (CS), generating a heatmap of the restulting matrix, and translating the final data matrix for network analysis in Cytoscape.

Cite as: Kellogg, JJ; Kvalheim, OM; Cech, NB (2019)
Composite score analysis for unsupervised comparison and network visualization of metabolomics data.
Analytica Chimica Acta, in press

### Load libraries
```{r Libraries}
library(tidyverse)
library(xlsx)
library(gplots)
library(ggfortify)
library(statsr)
```

## Loading and Preparing Data
- Import data from a .csv file and then removes the first column (removing non-numeric sample names from the dataset)
```{r Data import}
#import data
RAWdata <- read.csv(file.choose(),quote = "", row.names=NULL)
rnames <- RAWdata[,1]     # assign labels in column 1 to "rnames"
row.names(RAWdata) <- rnames
#remove first column
RAWdata.bare <- RAWdata[,-1]
```

### Data transformation2
- The data is traditionally transformed by the 4th root to improve any heteroscedastic noise. Note: not all datasets will require this transformation, and some will benefit from data transforms other than 4th root. 
```{r Transform data}
#transformation
rootdata <- abs(RAWdata.bare)^(0.25)
```

## PCA Analysis
Creates a PCA model of the data, and then extracts the scores and loadings

* To return the headers of the columns of the PCA plot
names(PCA.model)
  - [1] "sdev"     "rotation" "center"   "scale"    "x"
  - "x" - scores values
  - "rotation" - loadings values
  - "sdev" - standard deviation of the principal components (square roots of the eigenvalues of the correlation/covariance matrix)
```{r PCA model generation}
PCA.model <- prcomp(rootdata) #scale and center turned off... use 4th root data as is

#Extract the components necessary
scores <- PCA.model$x
loadings <- PCA.model$rotation
```

### Norm and Scaling 
- Each principal component (scores and loadings) of the PCA model is normed and scaled.
```{r Norm and scaling}
#calculate the norm of each column
euclidnorm <- function(x){return(sqrt(sum(x^2)))}

#apply to the scores
scorescale <- scale(scores, center=FALSE, scale=apply(scores, 2, euclidnorm))

#mean center and apply to loadings
loadscale <- scale(loadings, center=TRUE, scale=apply(loadings, 2, euclidnorm))
```

### Visualizing PCA model and determining optimum PCs
- To determine how many of the components from the PCA model are contributing to the model, multiple statistical analyses are employed:

#### Screeplot
```{r Analyzing PCA model}
# Empty table for final values
df <- data.frame(PCs=integer(),
                 stringsAsFactors=FALSE)
#screeplot
screeplot(PCA.model, npcs=ncol(scores))
plot(PCA.model, type="l") #screeplot with lines instead of histogram
```

#### Kaiser-Guttman rule, Jolliffe's modification of the Kaiser-Guttman rule, and Broken stick criterion
```{r Kaiser-Guttman}
# Eigenvalue by Kaiser-Guttman criterion
ev <- PCA.model$sdev^2
n = length(ev)
bsm = data.frame(j=seq(1:n), p=0)
bsm$p[1] = 1/n
for (i in 2:n) bsm$p[i] = bsm$p[i-1] + (1/(n + 1 - i))
bsm$p = 100*bsm$p/n
evplot = function(ev) {
  # Broken stick model (MacArthur 1957)
  n = length(ev)
  bsm = data.frame(j=seq(1:n), p=0)
  bsm$p[1] = 1/n
  for (i in 2:n) bsm$p[i] = bsm$p[i-1] + (1/(n + 1 - i))
  bsm$p = 100*bsm$p/n
  # Plot eigenvalues and % of variation for each axis
  op = par(mfrow=c(2,1),omi=c(0.1,0.3,0.1,0.1), mar=c(1, 1, 1, 1))
  barplot(ev, main="Eigenvalues", col="bisque", las=2)
  abline(h=mean(ev), col="red")
  legend("topright", "Average eigenvalue", lwd=1, col=2, bty="n")
  barplot(t(cbind(100*ev/sum(ev), bsm$p[n:1])), beside=TRUE, 
          main="% variation", col=c("bisque",2), las=2)
  legend("topright", c("% eigenvalue", "Broken stick model"), 
         pch=15, col=c("bisque",2), bty="n")
  par(op)
}
evplot(ev)

#Kaiser-Guttman Eigenvalue cut-off calculation
ev.mean <- mean(ev)
high.ev <- length(ev[ev > ev.mean])
newrow <- data.frame(PCs=high.ev)
df <- rbind(df, "Kaiser-Guttman" = newrow)

#Jolliffe's modification of Kaiser-Guttman
jkg <- 0.7 * ev.mean
jolliffe <- length(ev[ev > jkg])
newrow <- data.frame(PCs=jolliffe)
df <- rbind(df, "Jolliffe's KG" = newrow)

#Broken stick model calculation
broken <-(cbind(100*ev/sum(ev), bsm$p[n:1]))
broken <- as.data.frame(broken)
broken.res <- c(broken$V1 - broken$V2)
broke <- min(which(broken.res < 0)) - 1
newrow <- data.frame(PCs=broke)
df <- rbind(df, "Broken Stick Model" = newrow)
```
#### Parallel Analysis and Cattell's spree
```{r Parallel and Cattell}
#Parallel analysis and Cattell's scree
library(nFactors)
eigenvalues  <- PCA.model$sdev^2    # Extracts the observed eigenvalues
nsubjects    <- nrow(rootdata)      # Extracts the number of subjects
variables    <- length(eigenvalues) # Computes the number of variables
rep          <- 100                 # Number of replications for PA analysis
cent         <- 0.95                # Centile value of PA analysis

## PARALLEL ANALYSIS (qevpea for the centile criterion, mevpea for the
## mean criterion)
aparallel    <- nFactors::parallel(var     = variables,
                         subject = nsubjects, 
                         rep     = rep, 
                         cent    = cent
)$eigen$qevpea  # The 95 centile

## NUMBER OF FACTORS RETAINED ACCORDING TO DIFFERENT RULES
results      <- nScree(x=eigenvalues, aparallel=aparallel)

## PLOT ACCORDING TO THE nScree CLASS 
plotnScree(results)

final <- summary(results)
keeps <- c("noc", "naf", "nparallel")
final <- final[keeps]
cfinal <- t(final)
finalrownames <- c("Optimal Coordinates", "Acceleration Factor", "Parallel Analysis")
rownames(cfinal) <- finalrownames
newrow <- data.frame(PCs=cfinal)
df <- rbind(df, newrow)
```

#### User prompted to input the number of PCs desired to retain for the RCC calculation
```{r How many PCs?}
df
nopcs <- readline(prompt="How many princial components in the model?")
```
## Calcuate PC matrices and CS
Compute correlations across chosen principal components
```{r Calculate composite score}
PClist <- lapply(1:nopcs, # use 1:ncol(scorescale) if you want all the PCs to be used in the RCC
                 function(i) c(scorescale[,i]) %*% t(loadscale[,i]))
PCsum <- Reduce("+",PClist) #Sum all PCs to a single matrix
PCsumroot <- sweep(PCsum,2,colMeans(rootdata),"+") # Add in mean of the 4th root data for each variable (column)
Meanestmat <-scale(PCsumroot, center=TRUE, scale=FALSE) #Mean Estimated Matrix representing the PCA data

# dotprod <- Meanestmat %*% t(Meanestmat) # Calculate dotproduct of two matrices
normmem <- apply(Meanestmat,1,euclidnorm) # Calculate the norm of the Mean Estimated Matrix
# dotnorm <- normmem %*% t(normmem) # Dotproduct of the norm
CS <- (Meanestmat %*% t(Meanestmat))/(normmem %*% t(normmem))

```
## Heatmap
### Reassign the rownames (which were previously omitted)
```{r Prep Heatmap}
rnames <- RAWdata[,1]                       # assign labels in column 1 to "rnames"
heat.mat <- data.matrix(CS[,1:ncol(CS)])  # transform columns into a matrix
heat.mat <- round(heat.mat,3)
rownames(heat.mat) <- rnames                  # assign row names
colnames(heat.mat) <- rnames
```

### Plotting the heat map
```{r Plot heatmap}
# creates a personalized color palette
my_palette <- colorRampPalette(c("snow", "dodgerblue4"))(n = 299)

heatmap.2(heat.mat,
          #cellnote = round(heat.mat,3),  # Input Cell data in the middle, delete if not wanted same data set for cell labels
          notecex = 0.65,
          #main = "XXXX", # heat map title
          #notecol="black",      # change font color of cell labels to black
          key = T,
          #key.par = list(cex=),
          keysize = 0.1,
          key.title = NULL,
          key.xlab = NULL,
          key.ylab = NULL,
          #margins =c(4,4),      # widens margins around plot
          density.info="none",  # turns off density plot inside color legend
          #breaks=col_breaks,    # enable color transition at specified limits
          trace="none",         # turns off trace lines inside the heat map
          col=my_palette,       # use on color palette defined earlier
          dendrogram="row",     # only draw a row dendrogram
          Rowv=NULL,            # no row dendrogram
          Colv=NULL,          # no column dendogram
          #labCol=cnames,        # set column names
          cex.main = 0.75,
          lmat = rbind(c(3,4), c(2,1)), # set the order of the figure, which is a 2x2 matix: 1 - Heatmap,
          lwid = c(1,4),        # set column/row width default is c(1.5,4)
          lhei = c(5,15),        # set column/row height default is c(1.5,4)
          cexRow = 0.7,         # set font size in row
          cexCol = 0.7,        # set font size in column
          srtCol = 45,          #angle the column titlesn
         par(oma=c(0,0,0,0), mar=c(.25,.25,.25,.25), mgp=c(0,0,0)))
```

## Columnnating CS datamatrix 
- Converting the data, in a matrix format, into a columnar form for Cytoscape import and subsequent network analysis.
```{r Create Cytoscape matrix}
rnames <- RAWdata[,1]
rownames(CS) <- rnames
colnames(CS) <- rnames
CPCA <- as.vector(CS)
CPCA <- as.matrix(CPCA)

S1 <- rep(rnames,length.out = nrow(CPCA))
S1 <- as.matrix(S1)
S2 <- rep(rnames, each=ncol(CS))
S2 <- as.matrix(S2)
CPCA <- cbind(CPCA, S1, S2)

CPCA.final <- CPCA[,c(3,2,1)]
```